{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12489505,"sourceType":"datasetVersion","datasetId":7881424},{"sourceId":12489542,"sourceType":"datasetVersion","datasetId":7881453},{"sourceId":12489546,"sourceType":"datasetVersion","datasetId":7881456}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transformer-Based Title Generation - Part 2","metadata":{}},{"cell_type":"markdown","source":"This project presents a Transformer-based sequence-to-sequence model designed to generate book titles from book descriptions. The model architecture closely follows the encoder-decoder pattern popularized by the original Transformer framework, enriched with refinements such as label smoothing, custom loss masking and dynamic hyperparameter optimization.  \n  \nAt its core, the encoder processes the input description using token embeddings enriched with learnable positional encodings. The decoder generates the title autoregressively, guided by causal self-attention and encoder-decoder cross-attention mechanisms. Both encoder and decoder blocks use shared embeddings and incorporate residual connections, dropout regularization and layer normalization for stable training.  \n  \nA key highlight of this project is the integration of Optuna, an automated hyperparameter optimization framework. Optuna explores combinations of parameters such as embedding dimension, number of attention heads, model depth, dropout rate, learning rate and batch size. The objective function evaluates model performance using the ROUGE-1 score, a commonly used metric for evaluating short text generation tasks. It measures the overlap of unigrams (individual words) between the predicted and reference texts, making it well-suited for short outputs.  \n  \nTo avoid GPU memory overflow (OOM) during training, especially with large parameter combinations, the hyperparameter search space is carefully constrained to smaller, memory-efficient configurations. The best-performing model is checkpointed and later used for inference with a custom generation function that decodes tokens step-by-step until an end-of-sequence token is reached.","metadata":{}},{"cell_type":"markdown","source":"## Load and Prepare Data","metadata":{}},{"cell_type":"markdown","source":"The first part of this project begins by importing the preprocessed datasets generated in the previous project \"Transformer-Based Title Generation – Part 1\".  \n  \nTo prepare the data for training a Transformer-based model, we apply Byte Pair Encoding (BPE) for subword tokenization. BPE enables the model to handle rare and unknown words more effectively by breaking them into smaller, more frequent subunits. Special tokens such as pad, unk, sos and eos are added to the tokenizer to represent padding, unknown tokens, the start of a sequence and the end of a sequence, respectively.  \n  \nAfter tokenization, the sequences are further processed using the helper function create_decoder_inputs_and_targets(sequences, max_len, padding). This function separates the decoder input (which starts with sos and excludes eos) from the decoder target (which ends with eos and excludes sos). Padding is applied to ensure consistent input length across batches.  \n  \nThis structured preparation ensures that the model receives properly formatted inputs and targets during training, laying a solid foundation for the encoder-decoder architecture that follows in the next stages.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:17:38.997180Z","iopub.execute_input":"2025-07-20T15:17:38.997883Z","iopub.status.idle":"2025-07-20T15:17:41.332205Z","shell.execute_reply.started":"2025-07-20T15:17:38.997858Z","shell.execute_reply":"2025-07-20T15:17:41.331296Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"We're importing the preprocessed datasets made in Part 1.","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/train-book-data/train_book_data.csv')\ndf_valid = pd.read_csv('/kaggle/input/valid-book-data/valid_book_data.csv')\ndf_test = pd.read_csv('/kaggle/input/test-book-data/test_book_data.csv')\n\ndf_train.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:17:41.333487Z","iopub.execute_input":"2025-07-20T15:17:41.333823Z","iopub.status.idle":"2025-07-20T15:17:41.539632Z","shell.execute_reply.started":"2025-07-20T15:17:41.333803Z","shell.execute_reply":"2025-07-20T15:17:41.539084Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                              Title  \\\n1589                           howl and other poems   \n1590         crown of midnight (throne of glass #2)   \n1591      the cuckoo's calling (cormoran strike #1)   \n1592  saga, volume 2 (saga (collected editions) #2)   \n1593                             legend (legend #1)   \n\n                                            Description  \n1589  the prophetic poem, which was born by a genera...  \n1590  \"a line that should never be crossed is about ...  \n1591  a brilliant debut secret in a classic vein: a ...  \n1592  by the award-winning writer brian k. vaughan (...  \n1593  here there is an alternative title edition for...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1589</th>\n      <td>howl and other poems</td>\n      <td>the prophetic poem, which was born by a genera...</td>\n    </tr>\n    <tr>\n      <th>1590</th>\n      <td>crown of midnight (throne of glass #2)</td>\n      <td>\"a line that should never be crossed is about ...</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>the cuckoo's calling (cormoran strike #1)</td>\n      <td>a brilliant debut secret in a classic vein: a ...</td>\n    </tr>\n    <tr>\n      <th>1592</th>\n      <td>saga, volume 2 (saga (collected editions) #2)</td>\n      <td>by the award-winning writer brian k. vaughan (...</td>\n    </tr>\n    <tr>\n      <th>1593</th>\n      <td>legend (legend #1)</td>\n      <td>here there is an alternative title edition for...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"The following code prepares training and validation data for further processing. It extracts the columns from df_train and df_valid and converts them to strings. The columns are then transformed into Python lists so that they can be used more easily in downstream tasks.","metadata":{}},{"cell_type":"code","source":"# Prepare data\ntrain_titles = df_train[\"Title\"].astype(str).tolist()\ntrain_descriptions = df_train[\"Description\"].astype(str).tolist()\n\nvalid_titles = df_valid[\"Valid_Title\"].astype(str).tolist()\nvalid_descriptions = df_valid[\"Valid_Description\"].astype(str).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:17:43.943758Z","iopub.execute_input":"2025-07-20T15:17:43.944359Z","iopub.status.idle":"2025-07-20T15:17:43.950801Z","shell.execute_reply.started":"2025-07-20T15:17:43.944335Z","shell.execute_reply":"2025-07-20T15:17:43.950175Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"This code defines a helper function add_sos_eos that adds special tokens sos (start of sequence) and eos (end of sequence) to a text string if they are not already present. These tokens are used in sequence-to-sequence models to signal the beginning and end of a sentence.  \n  \nThe function is then applied to all elements in the train_titles list. This prepares the data for use in our model.","metadata":{}},{"cell_type":"code","source":"# Function to add <sos> (start of sequence) and <eos> (end of sequence) tokens\ndef add_sos_eos(text):\n    text = text.strip()  # Remove leading and trailing whitespace\n    if not text.startswith(\"<sos>\"):  # Check if text already starts with <sos>\n        text = f\"<sos> {text}\"  # Add <sos> at the beginning\n    if not text.endswith(\"<eos>\"):  # Check if text already ends with <eos>\n        text = f\"{text} <eos>\"  # Add <eos> at the end\n    return text\n\n# Apply the function to all training titles\ntrain_titles = [add_sos_eos(t) for t in train_titles]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:17:44.489241Z","iopub.execute_input":"2025-07-20T15:17:44.489795Z","iopub.status.idle":"2025-07-20T15:17:44.494318Z","shell.execute_reply.started":"2025-07-20T15:17:44.489770Z","shell.execute_reply":"2025-07-20T15:17:44.493579Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### BPE (Byte Pair Encoding)\n\n**Byte Pair Encoding (BPE)** is a subword tokenization technique that breaks words into smaller, more frequent units called subword tokens. Instead of treating each word as an atomic unit (as in traditional word-level tokenization), BPE starts with characters and gradually merges the most frequent adjacent pairs into new tokens, effectively learning a compact and expressive vocabulary.\n  \nBPE allows the model to handle rare or unseen words by decomposing them into known subwords. This reduces the number of out-of-vocabulary (OOV) tokens, which is crucial for robustness, especially when working with product data that may include brand names, technical terms or typos.  \nWith BPE, we can keep the vocabulary size relatively small without sacrificing the ability to represent complex words. This reduces memory usage and model complexity while maintaining flexibility.  \nBecause BPE reuses common subwords across many words (\"phone\", \"headphone\", \"smartphone\"), the model learns shared patterns more effectively. This improves generalization, especially in low-data settings.","metadata":{}},{"cell_type":"code","source":"from tokenizers import Tokenizer, models, pre_tokenizers, decoders, AddedToken, trainers\nfrom collections import Counter\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:17:49.998276Z","iopub.execute_input":"2025-07-20T15:17:49.998981Z","iopub.status.idle":"2025-07-20T15:18:10.789245Z","shell.execute_reply.started":"2025-07-20T15:17:49.998954Z","shell.execute_reply":"2025-07-20T15:18:10.788618Z"}},"outputs":[{"name":"stderr","text":"2025-07-20 15:17:52.947847: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753024673.316941      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753024673.422981      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"The following code sets up a Byte-Pair Encoding (BPE) tokenizer using the tokenizers library (from Hugging Face).\n\nWith models.BPE() a new BPE tokenizer model is created. The Whitespace pre-tokenizer pre_tokenizers.Whitespace() splits the input text into words based on spaces before applying BPE. This step helps the BPE model work more effectively.  \nThe BPEDecoder is assigned to convert the tokenized output back into readable text (for evaluation and inference).  \n  \nThis tokenizer will later be trained on text data and used to encode/decode sequences.","metadata":{}},{"cell_type":"code","source":"# Prepare the tokenizer\n# Initialize a Byte-Pair Encoding (BPE) tokenizer model\nbpe_tokenizer = Tokenizer(models.BPE())  \n\n# Use whitespace to split text into initial tokens before BPE is applied\nbpe_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()  \n\n# Use a BPE decoder to reconstruct original text from token IDs\nbpe_tokenizer.decoder = decoders.BPEDecoder()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:10.790544Z","iopub.execute_input":"2025-07-20T15:18:10.791069Z","iopub.status.idle":"2025-07-20T15:18:10.810417Z","shell.execute_reply.started":"2025-07-20T15:18:10.791047Z","shell.execute_reply":"2025-07-20T15:18:10.809589Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"The following function computes how often each token appears in a list of texts, based on the tokenizer's pre-tokenization step. It will be used for analyzing vocabulary distribution.\n  \n**Input:**  \ntexts: a list of strings. \ntokenizer: a tokenizer object with a defined pre_tokenizer.  \n  \n**Token Extraction:**  \nFor each text string, the function uses the pre_tokenize_str method, which returns a list of tuples where each tuple contains a token and its character span in the original string.  \n  \n**Counting Tokens:**  \nOnly the actual token string (token[0]) is used to update the frequency count via a Counter.  \n  \n**Output:**  \nA dictionary-like object mapping each token to the number of times it appears across all texts.","metadata":{}},{"cell_type":"code","source":"# Calculate token frequency\ndef calculate_token_frequencies(texts, tokenizer):\n    # Create a Counter to store token frequencies\n    token_counts = Counter()  \n    \n    for text in texts:\n        tokens = tokenizer.pre_tokenizer.pre_tokenize_str(text)  # Apply the tokenizer's pre-tokenizer to split the text\n        for token in tokens:\n            token_counts[token[0]] += 1  # Count the occurrence of each token (token[0] contains the actual string)\n            \n    return token_counts  # Return the frequency dictionary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:10.811142Z","iopub.execute_input":"2025-07-20T15:18:10.811383Z","iopub.status.idle":"2025-07-20T15:18:10.828727Z","shell.execute_reply.started":"2025-07-20T15:18:10.811358Z","shell.execute_reply":"2025-07-20T15:18:10.828160Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"The following steps determine how many unique tokens should be included in the Byte-Pair Encoding (BPE) tokenizer’s vocabulary to cover most of the dataset.\n  \n**Combine Data:**  \ntrain_titles and train_descriptions are merged to form one training corpus. Important because titles and descriptions could have different structures.  \n**Token Frequency Calculation:**  \nUses the calculate_token_frequencies function to count how often each token appears based on whitespace tokenization.    \n**Buffer for Subwords:**  \nThe number of unique tokens is used as the base vocabulary size. Since BPE can split rare or unknown words into subword units, the vocabulary size is increased to leave room for these subwords. This ensures the tokenizer can efficiently represent most of the data while also being flexible enough to handle rare or unknown terms.","metadata":{}},{"cell_type":"code","source":"# Combine texts (titles + descriptions)\ntrain_texts = train_titles + train_descriptions\n\n# Calculate vocabulary based on token frequencies using the previously defined function\ntoken_counts = calculate_token_frequencies(train_texts, bpe_tokenizer)\n\n# Vocab size with 20% buffer\nvocab_size = int(len(token_counts) * 1.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:13.479564Z","iopub.execute_input":"2025-07-20T15:18:13.480236Z","iopub.status.idle":"2025-07-20T15:18:14.061384Z","shell.execute_reply.started":"2025-07-20T15:18:13.480212Z","shell.execute_reply":"2025-07-20T15:18:14.060818Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"The following code finalizes and trains the Byte-Pair Encoding (BPE) tokenizer using the prepared training data.  \n  \n**Special Tokens:** A list of special-purpose tokens is defined. These are used for:  \npad: Padding shorter sequences  \nunk: Representing unknown words  \nsos and eos: Marking the beginning and end of sequences  \nThe lstrip=False and rstrip=False ensures the tokens are treated as standalone (not merged with surrounding text). \n  \n**Trainer Setup:** A BpeTrainer is initialized with:  \nThe vocabulary size calculated earlier.  \nThe list of special tokens to be included in the vocabulary.  \n  \n**Tokenizer Training:**  \nThe bpe_tokenizer.train_from_iterator(train_texts, trainer) function trains the tokenizer directly from the list of texts. It builds a BPE vocabulary and merge rules based on the token frequencies.\n  \nOnce trained, this tokenizer can tokenize and encode any new text using the same subword rules learned from train_texts.","metadata":{}},{"cell_type":"code","source":"# Define special tokens to be added to the tokenizer\nspecial_tokens = [\n    AddedToken(\"<pad>\", lstrip=False, rstrip=False),  # Padding token\n    AddedToken(\"<unk>\", lstrip=False, rstrip=False),  # Unknown token for unseen words\n    AddedToken(\"<sos>\", lstrip=False, rstrip=False),  # Start-of-sequence token\n    AddedToken(\"<eos>\", lstrip=False, rstrip=False),  # End-of-sequence token\n]\n\n# Initialize a BPE trainer with the desired vocabulary size and special tokens\ntrainer = trainers.BpeTrainer(\n    vocab_size=vocab_size,\n    special_tokens=special_tokens\n)\n\n# Train the BPE tokenizer on the combined training texts using the trainer\nbpe_tokenizer.train_from_iterator(train_texts, trainer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:14.187536Z","iopub.execute_input":"2025-07-20T15:18:14.187741Z","iopub.status.idle":"2025-07-20T15:18:14.848213Z","shell.execute_reply.started":"2025-07-20T15:18:14.187726Z","shell.execute_reply":"2025-07-20T15:18:14.847663Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"We can check the token IDs assigned to the special tokens after training our bpe_tokenizer using the .token_to_id() method.","metadata":{}},{"cell_type":"code","source":"# Print token IDs of the special tokens\nprint(\"Token IDs for special tokens:\")\nprint(\"<pad>:\", bpe_tokenizer.token_to_id(\"<pad>\"))\nprint(\"<unk>:\", bpe_tokenizer.token_to_id(\"<unk>\"))\nprint(\"<sos>:\", bpe_tokenizer.token_to_id(\"<sos>\"))\nprint(\"<eos>:\", bpe_tokenizer.token_to_id(\"<eos>\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:19.178297Z","iopub.execute_input":"2025-07-20T15:18:19.179204Z","iopub.status.idle":"2025-07-20T15:18:19.183485Z","shell.execute_reply.started":"2025-07-20T15:18:19.179181Z","shell.execute_reply":"2025-07-20T15:18:19.182733Z"}},"outputs":[{"name":"stdout","text":"Token IDs for special tokens:\n<pad>: 0\n<unk>: 1\n<sos>: 2\n<eos>: 3\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"The following function bpe_encode takes a list of texts and uses the trained BPE tokenizer to encode each into a list of token IDs.  \nThen, it pads all sequences to a specified max_length using post-padding (padding tokens are added to the end of each sequence).  \nThis ensures all sequences have the same length before being passed into a model.  \n  \nWith max_len_desc max_len_title we calculate the maximum tokenized sequence lengths using the BPE tokenizer","metadata":{}},{"cell_type":"code","source":"# Function to encode text using the BPE tokenizer and pad sequences to a uniform length\ndef bpe_encode(texts, tokenizer, max_length):\n    encodings = [tokenizer.encode(text).ids for text in texts]  # Encode each text and extract token IDs\n    return pad_sequences(encodings, maxlen=max_length, padding='post')  # Pad sequences to max_length using post-padding\n\n\n# Calculate maximum tokenized sequence lengths using the BPE tokenizer\nmax_len_desc = max(len(bpe_tokenizer.encode(text).ids) for text in train_descriptions + valid_descriptions)\nmax_len_title = max(len(bpe_tokenizer.encode(text).ids) for text in train_titles + valid_titles)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:19.769775Z","iopub.execute_input":"2025-07-20T15:18:19.770301Z","iopub.status.idle":"2025-07-20T15:18:20.506477Z","shell.execute_reply.started":"2025-07-20T15:18:19.770270Z","shell.execute_reply":"2025-07-20T15:18:20.505910Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"This block encodes and pads the training and validation datasets using the trained BPE tokenizer:  \n  \n**X_train / X_valid:** These are the inputs — encoded descriptions, padded to the maximum tokenized description length.  \n**y_train_full / y_valid_full:** These are the targets — encoded titles, padded to the maximum tokenized title length.  \n  \nThis prepares the data in a uniform shape suitable for training our sequence models.","metadata":{}},{"cell_type":"code","source":"# Encode and pad the training and validation data using the BPE tokenizer\nX_train = bpe_encode(train_descriptions, bpe_tokenizer, max_len_desc) \ny_train_full = bpe_encode(train_titles, bpe_tokenizer, max_len_title)\n\nX_valid = bpe_encode(valid_descriptions, bpe_tokenizer, max_len_desc)\ny_valid_full = bpe_encode(valid_titles, bpe_tokenizer, max_len_title)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:20.507443Z","iopub.execute_input":"2025-07-20T15:18:20.507684Z","iopub.status.idle":"2025-07-20T15:18:21.235620Z","shell.execute_reply.started":"2025-07-20T15:18:20.507657Z","shell.execute_reply":"2025-07-20T15:18:21.235060Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"The following function prepares the target sequences for a sequence-to-sequence decoder, where the full encoded title sequences padded to max_len_title is used as input.  \n  \nThe decoder input removes the last token (eos), so it becomes: [\"sos\", ..., token_n]  \nThe decoder target removes the first token (sos), so it becomes: [token_1, ..., \"eos\"]  \n  \nThis shift allows the model to learn to predict the next token at each step. Thas's called **Teacher forcing**. It is a training strategy used in decoder-based models. At each time step during training, the model receives the true previous token (from the target sequence) as input — rather than using the token it predicted at the previous step. This makes training faster and more stable, because the model doesn't compound its own mistakes during early training.  ","metadata":{}},{"cell_type":"code","source":"# Create decoder inputs and targets by shifting the sequences\ndef create_decoder_inputs_and_targets(sequences, max_len, padding):\n    decoder_input = []\n    decoder_target = []\n    \n    for seq in sequences:\n        # Remove trailing padding zeros\n        seq = [token for token in seq if token != 0]\n\n        # Apply standard shift logic if the sequence is long enough\n        if len(seq) >= 2:\n            decoder_input.append(seq[:-1])   # Remove <eos>: used as input to decoder. It is what the decoder sees.\n            decoder_target.append(seq[1:])   # Remove <sos>: expected target output. It is what the decoder predicts.\n        else:\n            # For very short sequences, append empty lists\n            decoder_input.append([])\n            decoder_target.append([])\n\n    # Pad both sequences to the desired max length\n    decoder_input_padded = pad_sequences(decoder_input, maxlen=max_len, padding=padding)\n    decoder_target_padded = pad_sequences(decoder_target, maxlen=max_len, padding=padding)\n    \n    return decoder_input_padded, decoder_target_padded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:25.096641Z","iopub.execute_input":"2025-07-20T15:18:25.096935Z","iopub.status.idle":"2025-07-20T15:18:25.102040Z","shell.execute_reply.started":"2025-07-20T15:18:25.096912Z","shell.execute_reply":"2025-07-20T15:18:25.101398Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"Both sequences are padded to the same length (max_len_title - 1) to align with training requirements.","metadata":{}},{"cell_type":"code","source":"# Generate decoder input and target sequences for training and validation\ndecoder_input_train, decoder_target_train = create_decoder_inputs_and_targets(\n    y_train_full, max_len=max_len_title - 1, padding='post'\n)\n\ndecoder_input_valid, decoder_target_valid = create_decoder_inputs_and_targets(\n    y_valid_full, max_len=max_len_title - 1, padding='post'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:25.587866Z","iopub.execute_input":"2025-07-20T15:18:25.588104Z","iopub.status.idle":"2025-07-20T15:18:25.753111Z","shell.execute_reply.started":"2025-07-20T15:18:25.588087Z","shell.execute_reply":"2025-07-20T15:18:25.752586Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Let's check whether each sequence in y_train_full starts with the token ID 2 and ends with the token ID 3.","metadata":{}},{"cell_type":"code","source":"for i, seq in enumerate(y_train_full):\n    if len(seq) == 0:\n        print(f\"Sequence {i} is empty.\")\n        continue\n\n    # Find the last non-zero token (ignoring padding)\n    last_nonzero = next((token for token in reversed(seq) if token != 0), None)\n\n    if seq[0] != 2 or last_nonzero != 3:\n        print(f\"Sequence {i} does not start with 2 or end with 3 (last non-zero: {last_nonzero}): {seq}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:26.403131Z","iopub.execute_input":"2025-07-20T15:18:26.403404Z","iopub.status.idle":"2025-07-20T15:18:26.532802Z","shell.execute_reply.started":"2025-07-20T15:18:26.403386Z","shell.execute_reply":"2025-07-20T15:18:26.532282Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Transformer Model\n  \nAt the heart of this project lies a custom encoder-decoder Transformer model, specifically designed to generate book titles from book descriptions. Inspired by the original Transformer architecture introduced in 2017, this model leverages attention mechanisms and positional encoding to effectively capture both local and global dependencies in sequences — making it ideal for text generation tasks.\n  \nThe model follows a sequence-to-sequence (seq2seq) structure composed of two primary components:\n\n**Encoder**:  \nThe encoder takes in the book description (already tokenized and padded) and processes it through multiple Transformer layers. Each layer includes multi-head self-attention, residual connections, layer normalization and feedforward sub-networks. These layers enable the encoder to build a rich, contextual representation of the input.  \n**Decoder**:  \nThe decoder receives the target sequence (starting with a <sos> token) and generates one token at a time. It includes both masked self-attention — preventing the model from seeing future tokens — and cross-attention layers that allow the decoder to attend to the encoder’s output. This dual attention mechanism ensures the decoder remains both autoregressive and context-aware.\n\n**Highlights**:  \n- A single embedding layer is shared between the encoder and decoder, ensuring consistent token representations and reducing the model’s memory footprint.  \n- A specialized loss function is implemented to apply label smoothing while ignoring padding tokens — a critical technique for stabilizing training and improving generalization.  \n- To avoid GPU memory issues, the model restricts certain hyperparameters (embedding dimension, number of layers/heads) to values that balance performance and hardware constraints.  ","metadata":{}},{"cell_type":"code","source":"pip install nlpaug transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:29.572518Z","iopub.execute_input":"2025-07-20T15:18:29.573039Z","iopub.status.idle":"2025-07-20T15:18:35.202279Z","shell.execute_reply.started":"2025-07-20T15:18:29.573015Z","shell.execute_reply":"2025-07-20T15:18:35.201480Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.2.3)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.13.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2025.4.26)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, Lambda\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import MultiHeadAttention\nfrom sklearn.model_selection import train_test_split\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:35.203905Z","iopub.execute_input":"2025-07-20T15:18:35.204127Z","iopub.status.idle":"2025-07-20T15:18:35.465935Z","shell.execute_reply.started":"2025-07-20T15:18:35.204107Z","shell.execute_reply":"2025-07-20T15:18:35.465359Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"The function that follows generates a **padding mask** for sequences, which is critical for models like transformers that use self-attention.\n  \nIt takes a batch of tokenized sequences (seq) as input. Then checks where tokens are equal to 0, which is the padding token ID.  \nReturns a mask with:  \n1.0 where padding exists (positions to ignore),  \n0.0 elsewhere (valid tokens).  \n  \nThe mask is reshaped to (batch_size, 1, 1, seq_len).  \nThis shape works with TensorFlow’s MultiHeadAttention layer as an additive mask, where +1.0 at padding positions will make attention logits very negative (after subtracting), effectively zeroing out attention to padding tokens.  \nWithout a mask, the model would attend to padding tokens — which are meaningless and could confuse the model.  ","metadata":{}},{"cell_type":"code","source":"# Create a padding mask to ignore padding tokens during attention\n@keras.utils.register_keras_serializable()  # Allows this function to be serialized with a Keras model\ndef create_padding_mask(seq):\n    # Create a binary mask: 1.0 where the token is padding, 0.0 elsewhere\n    mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n    \n    # Reshape to (batch_size, 1, 1, seq_len) for broadcasting in MultiHeadAttention\n    return mask[:, tf.newaxis, tf.newaxis, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:35.466768Z","iopub.execute_input":"2025-07-20T15:18:35.466983Z","iopub.status.idle":"2025-07-20T15:18:35.471048Z","shell.execute_reply.started":"2025-07-20T15:18:35.466967Z","shell.execute_reply":"2025-07-20T15:18:35.470500Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"The next function adds positional information to input embeddings so that the transformer model can understand the order of tokens in a sequence.  \n\nTransformers, by design, process all tokens in parallel and do not inherently know their positions. So this function adds trainable **positional embeddings** to the token embeddings.\n  \nExplanation:  \npositions = tf.range(...): Generates a list of positions from 0 to maxlen - 1.  \nEmbedding(...): Creates a layer where each position gets a learnable vector (same dimensionality as the token embeddings).  \nx + pos_embeddings: Adds the positional embedding to each token embedding, so the model receives combined information (word + position).  \n  \nSo if x is a tensor of shape (batch_size, sequence_length, embed_dim), the result after this function is a tensor of the same shape — but each token embedding now also contains positional context.","metadata":{}},{"cell_type":"code","source":"# Add positional encoding to input embeddings\n@keras.utils.register_keras_serializable()  # Allows this function to be serialized with a Keras model\ndef add_positional_encoding(x, maxlen, embed_dim):\n    # Generate position indices: [0, 1, 2, ..., maxlen-1]\n    positions = tf.range(start=0, limit=maxlen, delta=1)\n\n    # Create a trainable embedding layer for positions\n    pos_emb_layer = Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n    # Look up positional embeddings\n    pos_embeddings = pos_emb_layer(positions)\n\n    # Add positional embeddings to input embeddings\n    return x + pos_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:43.678088Z","iopub.execute_input":"2025-07-20T15:18:43.678795Z","iopub.status.idle":"2025-07-20T15:18:43.682865Z","shell.execute_reply.started":"2025-07-20T15:18:43.678769Z","shell.execute_reply":"2025-07-20T15:18:43.682241Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"The following function defines a universal **Transformer block**, usable for both encoder and decoder layers. It's modular and configurable via masking options.  \n  \n1. **Multi-Head Attention**:  \nAllows the model to attend to different parts of the sequence (or context) simultaneously. Can perform:  \nSelf-attention: when x == context  \nCross-attention: when x ≠ context (decoder attending to encoder outputs)  \nSupports two kinds of masking:  \nPadding mask: to ignore pad tokens  \nCausal mask: to prevent looking ahead (used in decoder self-attention)\n  \n2. **Residual + Layer Normalization**:  \nThe attention output is added to the input (x) via a residual connection, helping with gradient flow and convergence. \"Let the model learn something new, but also keep the original input.\" It prevents vanishing gradients in deep networks and allows easier flow of information from earlier layers to later layers. This way it helps the model learn refinements instead of completely new representations.  \nLayerNormalization stabilizes training. It normalizes the values across the features within each training example. This stabilizes training by ensuring the outputs of layers have similar distributions and thus reduces the risk of exploding/vanishing activations.  \n  \n3. **Feed-Forward Network (FFN)**:  \nApplies two Dense layers:  \nFirst with ReLU activation (ff_dim size),  \nSecond to project back to embed_dim.  \nThis captures nonlinear transformations of each token independently.\n  \n4. **Second Residual + Layer Norm**:  \nAdds the FFN output to the attention output (out1) — another residual connection.  \nEnds with another LayerNormalization, completing the block.  ","metadata":{}},{"cell_type":"code","source":"# Universal Transformer block with optional padding and causal masking\n@keras.utils.register_keras_serializable()  # Allows this function to be serialized with a Keras model\ndef transformer_block(x, context, embed_dim, num_heads, ff_dim, dropout_rate, use_causal_mask=False, padding_mask=None):\n    # Multi-head self-attention\n    attn_output = MultiHeadAttention(\n        num_heads=num_heads,\n        key_dim=embed_dim,\n        dropout=dropout_rate\n    )(\n        query=x, \n        value=context, \n        key=context, \n        attention_mask=padding_mask, \n        use_causal_mask=use_causal_mask\n    )\n    # x: used as the query\n    # context: used as key and value:\n    #   • In encoder self-attention: x == context\n    #   • In decoder self-attention: x == context, with causal mask\n    #   • In encoder-decoder attention: context is the encoder output\n    # padding_mask: prevents attention to padding tokens\n    # use_causal_mask: prevents attending to future tokens (for decoder self-attention)\n\n    # Apply dropout and add residual connection\n    attn_output = Dropout(dropout_rate)(attn_output)\n    out1 = LayerNormalization(epsilon=1e-6)(x + attn_output)\n    # Residual connection: adds original input `x` to attention output\n    # Followed by Layer Normalization\n\n    # Feed-forward network (position-wise)\n    ffn_output = Dense(ff_dim, activation='relu')(out1)\n    ffn_output = Dense(embed_dim)(ffn_output)\n    ffn_output = Dropout(dropout_rate)(ffn_output)\n\n    # Second residual connection and normalization\n    return LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n    # Second residual connection: output of attention + FFN\n    # Final LayerNorm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:44.370490Z","iopub.execute_input":"2025-07-20T15:18:44.371046Z","iopub.status.idle":"2025-07-20T15:18:44.376471Z","shell.execute_reply.started":"2025-07-20T15:18:44.371023Z","shell.execute_reply":"2025-07-20T15:18:44.375771Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"The next function creates and returns a custom loss function for training language models that:  \n- Smooths the labels (label smoothing)  \n- Ignores padding tokens (masking)  \n- Is compatible with Keras serialization  \n  \nThis prevents the model from becoming too confident in its predictions and helps generalization and reduces overfitting.  \nInstead of a \"hard\" 1-hot vector (e.g., [0, 0, 1, 0]), it produces a softer version (e.g., [0.01, 0.01, 0.96, 0.01]).  \nSequences are padded to a fixed length and padding tokens (ID=0) are not real data and should not influence training. So the mask ensures loss is only calculated on real tokens.","metadata":{}},{"cell_type":"code","source":"# Returns a custom loss function with label smoothing and masking for padding\ndef get_masked_label_smoothing_loss(smoothing):\n    @keras.utils.register_keras_serializable()  # Allows this function to be serialized with a Keras model\n    def loss_fn(y_true, y_pred):\n        # Cast true labels to integers\n        y_true = tf.cast(y_true, tf.int32)\n\n        # Get vocabulary size from the prediction tensor's last dimension\n        vocab_size = tf.shape(y_pred)[-1]\n\n        # Convert true labels to one-hot encoding\n        y_true_one_hot = tf.one_hot(y_true, vocab_size)\n\n        # Apply label smoothing:\n        #  - Distribute (smoothing) probability mass across all classes\n        #  - Keep (1 - smoothing) on the correct class\n        y_true_smoothed = y_true_one_hot * (1 - smoothing) + (smoothing / tf.cast(vocab_size, tf.float32))\n\n        # Compute cross-entropy loss between smoothed labels and predictions\n        loss = tf.keras.losses.categorical_crossentropy(y_true_smoothed, y_pred)\n\n        # Create a mask to ignore padding tokens (padding ID = 0)\n        mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n\n        # Apply the mask to the loss\n        loss *= mask\n\n        # Return mean loss over non-padding tokens\n        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n    \n    return loss_fn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:45.182963Z","iopub.execute_input":"2025-07-20T15:18:45.183612Z","iopub.status.idle":"2025-07-20T15:18:45.188445Z","shell.execute_reply.started":"2025-07-20T15:18:45.183591Z","shell.execute_reply":"2025-07-20T15:18:45.187849Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"The following function create_encoder_decoder_transformer() defines a complete Transformer-based encoder-decoder model tailored for sequence-to-sequence tasks. It is designed to work with Optuna, a hyperparameter optimization framework, which automatically explores different configurations to find the best-performing model.  \n\nThe model follows the classical Transformer encoder-decoder structure. The encoder processes the input sequence and the decoder generates the target sequence, one token at a time. The encoder and decoder both receive tokenized sequences as input, where each token is represented by its corresponding integer ID. These inputs are fed into a shared embedding layer that maps each token ID to a dense vector of embedding dimension size. The model uses shared embeddings to save memory and ensure consistent token representations across both encoder and decoder.\n  \nAt the beginning of the function, several hyperparameters are sampled using Optuna’s trial object. These include the number of **attention heads (num_heads)**, the **embedding dimension (embed_dim)**, the **size of the feedforward network** inside each Transformer block (ff_dim), the **number of Transformer layers (num_layers)**, the **dropout rate (dropout_rate)**, the **initial learning rate for the optimizer (initial_lr)**, the **label smoothing factor (smoothing)** and the **batch size (batch_size)**. One important constraint enforced here is that the embedding dimension must be divisible by the number of heads, which is necessary for multi-head attention to function correctly.  \n\nThe **learning rate schedule** defined here is effectively never used in practice. The reason is that the dataset is very small (only 1,593 training samples), so there aren't many training steps in total. With such a limited dataset, the model is prone to overfitting very quickly. If the learning rate decays during training, it would only make it harder for the optimizer to escape overfitting once it starts. In addition, with the current setting of decay_steps=10000 and staircase=True the learning rate will never decay at all, since training ends long before reaching 10,000 steps.  \nFor a meaningful schedule, both decay_steps and a final learning rate should also be part of the hyperparameter optimization. Only with a larger dataset would it make sense to experiment with an actual learning rate decay strategy. The initial_lr is still optimized.  \n  \nThe encoder consists of a stack of Transformer blocks, each of which includes multi-head self-attention and a feedforward network. These blocks allow the model to learn dependencies between all tokens in the input sequence, regardless of their position.\n  \nThe decoder is also composed of a stack of Transformer blocks but with a slightly different structure. Each decoder block first applies masked self-attention, which ensures that the decoder can only attend to earlier tokens in the sequence (**causal masking**). This is critical for autoregressive generation, where the model predicts one token at a time based on previously generated ones. After that, cross-attention is applied, where the decoder attends to the encoder’s output. This allows the decoder to focus on relevant parts of the input when generating each output token.\n  \nPadding masks are used in both the encoder and decoder to prevent the model from attending to padded positions in the sequences. These masks are passed into the attention layers and are essential for handling sequences of variable length in a batch.\n  \nAfter processing through the encoder and decoder, the output is passed through a final dense layer with a softmax activation to predict the probability distribution over the vocabulary for each position in the output sequence.\n  \nThe model is compiled using the **Adam optimizer** with an exponentially decaying learning rate, which starts higher and decreases over time to stabilize training. The loss function used applies label smoothing (to avoid overconfidence in predictions) and masks out loss contributions from padded positions (to ensure padding tokens do not affect the gradients).\n  \nFinally, the function returns the compiled model along with the batch size sampled by Optuna. The use of K.clear_session() ensures that memory is properly cleared between trials.","metadata":{}},{"cell_type":"code","source":"@keras.utils.register_keras_serializable()  # Allows this function to be serialized with a Keras model\ndef create_encoder_decoder_transformer(trial):\n    # Clear backend to avoid memory leaks in repeated trials\n    K.clear_session() \n    \n    # Define hyperparameter search space using Optuna\n    num_heads = trial.suggest_categorical(\"num_heads\", [2, 4])\n\n    # Ensure that embed_dim is divisible by num_heads and <= 256\n    valid_embed_dims = [d for d in range(96, 257, 32) if d % num_heads == 0]\n    embed_dim = trial.suggest_categorical(\"embed_dim\", valid_embed_dims)\n\n    ff_dim = trial.suggest_int(\"ff_dim\", 96, 160, step=16)\n    num_layers = trial.suggest_int('num_layers', 2, 3)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4)\n    initial_lr = trial.suggest_float(\"initial_lr\", 1e-4, 5e-4, log=True)\n    smoothing = trial.suggest_float('smoothing', 0.1, 0.3)\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n\n    # Encoder and decoder input layers\n    encoder_inputs = Input(shape=(max_len_desc,), name='encoder_inputs')\n    decoder_inputs = Input(shape=(max_len_title - 1,), name='decoder_inputs')\n\n    # Create padding masks for attention mechanisms\n    enc_padding_mask = Lambda(create_padding_mask)(encoder_inputs)\n    dec_padding_mask = Lambda(create_padding_mask)(decoder_inputs)\n\n    # Shared token embedding layer for both encoder and decoder\n    token_embedding = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n\n    # --- Encoder ---\n    x_enc = token_embedding(encoder_inputs)\n    x_enc = add_positional_encoding(x_enc, max_len_desc, embed_dim)\n\n    for _ in range(num_layers):\n        # Transformer encoder block with self-attention: x = context = x_enc\n        x_enc = transformer_block(\n            x_enc, x_enc,\n            embed_dim, num_heads, ff_dim, dropout_rate,\n            padding_mask=enc_padding_mask\n        )\n\n    # --- Decoder ---\n    x_dec = token_embedding(decoder_inputs)\n    x_dec = add_positional_encoding(x_dec, max_len_title - 1, embed_dim)\n\n    for _ in range(num_layers):\n        # Masked self-attention: decoder looks only at previous tokens\n        x_dec = transformer_block(\n            x_dec, x_dec,\n            embed_dim, num_heads, ff_dim, dropout_rate,\n            use_causal_mask=True, # Cannot look into future\n            padding_mask=dec_padding_mask\n        )\n\n        # Encoder-decoder attention: decoder focuses on encoder context: x = x_dec and context = x_enc\n        x_dec = transformer_block(\n            x_dec, x_enc,\n            embed_dim, num_heads, ff_dim, dropout_rate,\n            padding_mask=enc_padding_mask\n        )\n\n    # Final output layer: vocabulary distribution\n    outputs = Dense(vocab_size, activation='softmax')(x_dec)\n\n    # Build and compile the model\n    model = Model([encoder_inputs, decoder_inputs], outputs)\n\n    # Learning rate schedule with exponential decay --> schedule not used here, please see text above!\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=initial_lr,\n        decay_steps=10000,\n        decay_rate=0.1,\n        staircase=True\n    )\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\n    # Loss with label smoothing and padding mask\n    loss_fn = get_masked_label_smoothing_loss(smoothing)\n\n    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n\n    return model, batch_size\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:50.970348Z","iopub.execute_input":"2025-07-20T15:18:50.970879Z","iopub.status.idle":"2025-07-20T15:18:50.980544Z","shell.execute_reply.started":"2025-07-20T15:18:50.970854Z","shell.execute_reply":"2025-07-20T15:18:50.979794Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## OPTUNA with ROUGE-Score\n  \n**Optuna** is a powerful framework for automated hyperparameter optimization, especially well-suited for deep learning models. When applied to natural language processing (NLP) tasks, it can explore a wide range of model configurations to improve evaluation metrics such as the **ROUGE score**. ROUGE stands for **Recall-Oriented Understudy for Gisting Evaluation**. It's a family of metrics widely used to evaluate automatic text generation tasks. It compares a generated text (our model’s output) against a reference or \"gold standard\". By using ROUGE instead of just validation loss, we're aligning model selection with actual generation performance — making the hyperparameter tuning much more meaningful. Specifically, we use the **ROUGE-1** score. A commonly used metric for evaluating short text generation tasks. It measures the overlap of unigrams (individual words) between the predicted and reference texts, making it well-suited for short, concise outputs. \n  \nTypically, Optuna will try different values for architectural hyperparameters. Once a model is trained with a specific configuration, we evaluate it on a validation set and compute the ROUGE score. Optuna uses this score as the objective function to maximize, guiding it toward more effective model architectures.","metadata":{}},{"cell_type":"markdown","source":"However, our Optuna trial was failing because the model is too large to fit into GPU memory. This is commonly referred to as an Out of Memory (OOM) error.  \n  \nThis typically happens when Optuna samples a combination of hyperparameters that results in a model with too many trainable parameters. The most common culprits are a very large embedding dimensions (512 or 1024), a high number of attention heads (which scale memory with embed_dim / num_heads) and too many Transformer layers in the encoder and decoder.  \nAll of these increase the model size quadratically or worse and memory usage can spike sharply.  \n\nTo prevent OOM errors and allow our optimization process to run reliably, we limit the upper bounds of memory-intensive hyperparameters. With these constraints, our model will be less likely to exceed available GPU memory and Optuna can run more trials without crashing. The results are smaller models, therefore we pair it with label smoothing, dropout and a good learning rate schedule.","metadata":{}},{"cell_type":"code","source":"pip install optuna-integration","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:51.870128Z","iopub.execute_input":"2025-07-20T15:18:51.870406Z","iopub.status.idle":"2025-07-20T15:18:55.158165Z","shell.execute_reply.started":"2025-07-20T15:18:51.870386Z","shell.execute_reply":"2025-07-20T15:18:55.157399Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting optuna-integration\n  Downloading optuna_integration-4.4.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration) (4.3.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (1.15.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (2.0.40)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.13.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration) (3.1.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna->optuna-integration) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna->optuna-integration) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna->optuna-integration) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna->optuna-integration) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna->optuna-integration) (2024.2.0)\nDownloading optuna_integration-4.4.0-py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: optuna-integration\nSuccessfully installed optuna-integration-4.4.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"pip install rouge-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:18:55.159679Z","iopub.execute_input":"2025-07-20T15:18:55.159964Z","iopub.status.idle":"2025-07-20T15:19:00.123613Z","shell.execute_reply.started":"2025-07-20T15:18:55.159942Z","shell.execute_reply":"2025-07-20T15:19:00.122854Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge-score) (2024.2.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=1720033671e34f06125745ae085f7bb43518c39c571a4f097e53c9ff0cda7894\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import optuna\nfrom rouge_score import rouge_scorer\nimport optuna.visualization as vis\nfrom optuna.integration import TFKerasPruningCallback\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.models import load_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:19:00.124510Z","iopub.execute_input":"2025-07-20T15:19:00.124809Z","iopub.status.idle":"2025-07-20T15:19:02.504643Z","shell.execute_reply.started":"2025-07-20T15:19:00.124785Z","shell.execute_reply":"2025-07-20T15:19:02.503688Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"The following code defines a full Optuna-compatible objective function for training and evaluating our Transformer model using ROUGE-1 as the evaluation metric. The goal is to tune hyperparameters to maximize the quality of generated text as measured by how well they match ground truth references.  \n\nThe code includes three main components:  \n  \n1. Decoding sequences of token IDs into readable text: **decode_sequences(pred_sequences, tokenizer):**  \nA helper function that ensures that model outputs (which are sequences of token IDs) are converted back into plain text strings. It stops at the padding or end-of-sequence token (ID 0) and uses the tokenizer to decode the token list into text. This step is crucial before comparing generated output with reference texts using ROUGE.  \n   \n2. Calculating average ROUGE-1 score between model predictions and ground truth: **compute_avg_rouge_l_score(y_true_texts, y_pred_texts):**  \nThis function computes the average ROUGE-1 F1 score over a list of reference texts and predicted texts. ROUGE-1 measures the overlap of individual words between the predicted and reference texts, rewarding overlapping sequence.  \nThe use of use_stemmer=True ensures that inflectional variants like \"run\" and \"running\" are treated as similar, improving metric robustness.\n  \n3. Training the model, generating predictions and returning the evaluation score to Optuna: **seq2seq_objective(trial):**  \n- This function calls our model-building function (create_encoder_decoder_transformer) that constructs a Transformer-based encoder-decoder model using hyperparameters suggested by Optuna and also returns the batch size.  \n- **TFKerasPruningCallback** allows Optuna to stop unpromising trials early if validation loss doesn’t improve — saving time and GPU resources.  \n- **EarlyStopping** ensures training ends early if no validation loss improvement is observed, and restores the best model weights.   \n- decoder_input_train contains the decoder input tokens (starting with sos), while decoder_target_train contains the actual output tokens the model should learn to predict.  \n- Validation data is used for early stopping and pruning.  \n- After training, the model generates probability distributions over the vocabulary for each output token position.  \n- **argmax** selects the most likely token at each step, resulting in a matrix of predicted token IDs.  \n- The token sequences are decoded back into text using the earlier function, so ROUGE can compare strings.  \n- The average ROUGE-1 score is computed for the batch of validation examples.  \n- This score is returned to Optuna, which tries to maximize it.  ","metadata":{}},{"cell_type":"code","source":"def decode_sequences(pred_sequences, tokenizer):\n    texts = []\n    for seq in pred_sequences:\n        if isinstance(seq, np.ndarray):\n            seq = seq.tolist()  # Ensure the sequence is a list\n\n        # Cut the sequence at the first padding or end-of-sequence token (ID = 0)\n        try:\n            end_idx = seq.index(0)\n            seq = seq[:end_idx]\n        except ValueError:\n            pass  # No padding found; use full sequence\n\n        # Convert token IDs to text, skipping special tokens like <pad>, <sos>, <eos>\n        texts.append(tokenizer.decode(seq, skip_special_tokens=True))\n    return texts\n\n\ndef compute_avg_rouge_1_score(y_true_texts, y_pred_texts):\n    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n    scores = []\n    for ref, pred in zip(y_true_texts, y_pred_texts):\n        score = scorer.score(ref, pred)['rouge1'].fmeasure\n        scores.append(score)\n    return np.mean(scores)\n\ndef seq2seq_objective(trial):\n    model, batch_size = create_encoder_decoder_transformer(trial)\n\n    callbacks = [\n        TFKerasPruningCallback(trial, 'val_loss'), \n        EarlyStopping(patience=7, monitor='val_loss', restore_best_weights=True)\n    ]\n\n    model.fit(\n        [X_train, decoder_input_train],\n        decoder_target_train,\n        validation_data=([X_valid, decoder_input_valid], decoder_target_valid),\n        epochs=8,  # 8 epochs are eoungh because the dataset is small an we want to prevent overfitting\n        batch_size=batch_size,\n        callbacks=callbacks,\n        verbose=1\n    )\n\n    # model generates probability distributions over the vocabulary\n    predictions = model.predict([X_valid, decoder_input_valid], batch_size=batch_size)\n    predicted_ids = np.argmax(predictions, axis=-1)\n\n    # token sequences are decoded back into text \n    predicted_texts = decode_sequences(predicted_ids, bpe_tokenizer)\n    reference_texts = decode_sequences(decoder_target_valid, bpe_tokenizer)\n\n    # average ROUGE-1 score is computed for the batch of validation examples\n    avg_rouge = compute_avg_rouge_1_score(reference_texts, predicted_texts)\n\n    # score is returned to Optuna, which tries to maximize it\n    return avg_rouge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:19:14.073030Z","iopub.execute_input":"2025-07-20T15:19:14.073595Z","iopub.status.idle":"2025-07-20T15:19:14.080723Z","shell.execute_reply.started":"2025-07-20T15:19:14.073575Z","shell.execute_reply":"2025-07-20T15:19:14.079997Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"With **optuna.create_study(direction=\"maximize\")** we create a new optimization study object. We specify direction=\"maximize\" because the goal is to maximize the average ROUGE-1 score returned by our seq2seq_objective() function.  \nThis study will keep track of trials, monitor the best score so far and allow us to inspect results later.\n  \n**study.optimize(seq2seq_objective, n_trials=x)** triggers the optimization loop for n_trials. Optuna will run x different model configurations.  \nIn each trial Optuna samples a set of hyperparameters (like embed_dim, num_heads, dropout_rate, etc.). The seq2seq_objective() function builds and trains the model using those settings. It then decodes predictions and computes the average ROUGE-1 score on the validation set. That score is reported back to Optuna as the trial's objective value.  \nOptuna uses this feedback to explore more promising regions of the search space in later trials.","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(seq2seq_objective, n_trials=5)\n\n# Display the best hyperparameters found\nprint('Best hyperparameters: ', study.best_params)\n\n# Display the best average ROUGE score achieved\nprint('Best avg_rouge: ', study.best_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:19:22.972919Z","iopub.execute_input":"2025-07-20T15:19:22.973448Z","iopub.status.idle":"2025-07-20T16:06:58.057073Z","shell.execute_reply.started":"2025-07-20T15:19:22.973424Z","shell.execute_reply":"2025-07-20T16:06:58.056370Z"}},"outputs":[{"name":"stderr","text":"[I 2025-07-20 15:19:22,974] A new study created in memory with name: no-name-ab9a42fe-a843-4b8f-af0a-165d93e3ebf5\nI0000 00:00:1753024765.572945      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1753024765.573667      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1753024793.062209     104 service.cc:148] XLA service 0x7faa7c00c820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1753024793.063779     104 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1753024793.063797     104 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1753024795.339133     104 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1753024815.485146     104 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 445ms/step - accuracy: 0.0159 - loss: 8.2658 - val_accuracy: 0.0035 - val_loss: 8.3035\nEpoch 2/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 370ms/step - accuracy: 0.0334 - loss: 7.0656 - val_accuracy: 0.0162 - val_loss: 8.2023\nEpoch 3/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 367ms/step - accuracy: 0.0490 - loss: 6.5693 - val_accuracy: 0.0182 - val_loss: 8.2227\nEpoch 4/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 366ms/step - accuracy: 0.0582 - loss: 6.2217 - val_accuracy: 0.0253 - val_loss: 8.0609\nEpoch 5/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 368ms/step - accuracy: 0.0612 - loss: 6.0167 - val_accuracy: 0.0257 - val_loss: 8.0848\nEpoch 6/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 369ms/step - accuracy: 0.0692 - loss: 5.7181 - val_accuracy: 0.0253 - val_loss: 8.1824\nEpoch 7/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 370ms/step - accuracy: 0.0754 - loss: 5.5147 - val_accuracy: 0.0245 - val_loss: 8.2023\nEpoch 8/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 370ms/step - accuracy: 0.0861 - loss: 5.2375 - val_accuracy: 0.0255 - val_loss: 8.2401\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 361ms/step\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-20 15:30:28,694] Trial 0 finished with value: 0.02078787878787879 and parameters: {'num_heads': 4, 'embed_dim': 256, 'ff_dim': 128, 'num_layers': 2, 'dropout_rate': 0.3119638403630194, 'initial_lr': 0.0004017722178202516, 'smoothing': 0.28319536438853843, 'batch_size': 8}. Best is trial 0 with value: 0.02078787878787879.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 625ms/step - accuracy: 0.0106 - loss: 9.5747 - val_accuracy: 0.0000e+00 - val_loss: 9.0738\nEpoch 2/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 297ms/step - accuracy: 0.0167 - loss: 8.5785 - val_accuracy: 0.0000e+00 - val_loss: 8.5350\nEpoch 3/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 296ms/step - accuracy: 0.0167 - loss: 7.8331 - val_accuracy: 0.0000e+00 - val_loss: 8.2818\nEpoch 4/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 281ms/step - accuracy: 0.0167 - loss: 7.4089 - val_accuracy: 0.0000e+00 - val_loss: 8.2227\nEpoch 5/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 289ms/step - accuracy: 0.0170 - loss: 7.2536 - val_accuracy: 1.6667e-04 - val_loss: 8.2009\nEpoch 6/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 289ms/step - accuracy: 0.0220 - loss: 7.1552 - val_accuracy: 0.0037 - val_loss: 8.1307\nEpoch 7/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 288ms/step - accuracy: 0.0262 - loss: 7.0826 - val_accuracy: 0.0048 - val_loss: 8.0645\nEpoch 8/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 288ms/step - accuracy: 0.0281 - loss: 6.9492 - val_accuracy: 0.0110 - val_loss: 8.0285\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 675ms/step\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-20 15:36:05,571] Trial 1 finished with value: 0.024136363636363633 and parameters: {'num_heads': 2, 'embed_dim': 96, 'ff_dim': 112, 'num_layers': 3, 'dropout_rate': 0.16991901568662465, 'initial_lr': 0.0001063424846168355, 'smoothing': 0.24867264327584324, 'batch_size': 16}. Best is trial 1 with value: 0.024136363636363633.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.0154 - loss: 8.6039 - val_accuracy: 0.0000e+00 - val_loss: 8.1665\nEpoch 2/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 841ms/step - accuracy: 0.0217 - loss: 6.9301 - val_accuracy: 0.0105 - val_loss: 8.0301\nEpoch 3/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 833ms/step - accuracy: 0.0371 - loss: 6.4795 - val_accuracy: 0.0127 - val_loss: 7.8999\nEpoch 4/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 827ms/step - accuracy: 0.0442 - loss: 6.2150 - val_accuracy: 0.0060 - val_loss: 8.0685\nEpoch 5/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 831ms/step - accuracy: 0.0452 - loss: 6.1113 - val_accuracy: 0.0148 - val_loss: 8.0182\nEpoch 6/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 834ms/step - accuracy: 0.0473 - loss: 6.0045 - val_accuracy: 0.0150 - val_loss: 8.0552\nEpoch 7/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 835ms/step - accuracy: 0.0499 - loss: 5.8853 - val_accuracy: 0.0178 - val_loss: 8.1299\nEpoch 8/8\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 833ms/step - accuracy: 0.0481 - loss: 5.8695 - val_accuracy: 0.0163 - val_loss: 8.1288\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 827ms/step\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-20 15:49:06,648] Trial 2 finished with value: 0.01500865800865801 and parameters: {'num_heads': 4, 'embed_dim': 160, 'ff_dim': 112, 'num_layers': 3, 'dropout_rate': 0.38441584404767315, 'initial_lr': 0.0004708707267234865, 'smoothing': 0.20519753407428126, 'batch_size': 16}. Best is trial 1 with value: 0.024136363636363633.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.0126 - loss: 9.3495 - val_accuracy: 0.0000e+00 - val_loss: 8.5253\nEpoch 2/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.0167 - loss: 7.7421 - val_accuracy: 0.0000e+00 - val_loss: 8.2559\nEpoch 3/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.0191 - loss: 7.1882 - val_accuracy: 0.0042 - val_loss: 8.1924\nEpoch 4/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.0300 - loss: 6.9880 - val_accuracy: 0.0137 - val_loss: 8.0090\nEpoch 5/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.0392 - loss: 6.7860 - val_accuracy: 0.0185 - val_loss: 7.8409\nEpoch 6/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.0492 - loss: 6.5054 - val_accuracy: 0.0208 - val_loss: 7.8498\nEpoch 7/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.0544 - loss: 6.2724 - val_accuracy: 0.0243 - val_loss: 7.7706\nEpoch 8/8\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.0593 - loss: 6.0895 - val_accuracy: 0.0255 - val_loss: 7.7381\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-20 15:57:36,501] Trial 3 finished with value: 0.040728354978354975 and parameters: {'num_heads': 2, 'embed_dim': 192, 'ff_dim': 128, 'num_layers': 3, 'dropout_rate': 0.3315688244224434, 'initial_lr': 0.000441391965261028, 'smoothing': 0.24813453584489864, 'batch_size': 64}. Best is trial 3 with value: 0.040728354978354975.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 422ms/step - accuracy: 0.0159 - loss: 8.5559 - val_accuracy: 0.0063 - val_loss: 8.0363\nEpoch 2/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 308ms/step - accuracy: 0.0355 - loss: 6.7849 - val_accuracy: 0.0195 - val_loss: 7.8575\nEpoch 3/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 297ms/step - accuracy: 0.0517 - loss: 6.2955 - val_accuracy: 0.0240 - val_loss: 7.7504\nEpoch 4/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 299ms/step - accuracy: 0.0588 - loss: 5.9336 - val_accuracy: 0.0282 - val_loss: 7.7042\nEpoch 5/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 300ms/step - accuracy: 0.0666 - loss: 5.6606 - val_accuracy: 0.0300 - val_loss: 7.6847\nEpoch 6/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 300ms/step - accuracy: 0.0722 - loss: 5.3810 - val_accuracy: 0.0290 - val_loss: 7.6992\nEpoch 7/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 301ms/step - accuracy: 0.0774 - loss: 5.1417 - val_accuracy: 0.0305 - val_loss: 7.6828\nEpoch 8/8\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 301ms/step - accuracy: 0.0828 - loss: 4.9553 - val_accuracy: 0.0293 - val_loss: 7.7456\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-20 16:06:58,052] Trial 4 finished with value: 0.05017532467532467 and parameters: {'num_heads': 4, 'embed_dim': 192, 'ff_dim': 112, 'num_layers': 2, 'dropout_rate': 0.12395474756144638, 'initial_lr': 0.0002057299316110685, 'smoothing': 0.2324882314383764, 'batch_size': 8}. Best is trial 4 with value: 0.05017532467532467.\n","output_type":"stream"},{"name":"stdout","text":"Best hyperparameters:  {'num_heads': 4, 'embed_dim': 192, 'ff_dim': 112, 'num_layers': 2, 'dropout_rate': 0.12395474756144638, 'initial_lr': 0.0002057299316110685, 'smoothing': 0.2324882314383764, 'batch_size': 8}\nBest avg_rouge:  0.05017532467532467\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Our Transformer model training through Optuna shows some progress over the trials.","metadata":{}},{"cell_type":"markdown","source":"With **best_trial = study.best_trial** we retrieve the best trial from the study — that is, the one that achieved the highest average ROUGE-1 score across all evaluated configurations. With this object we'll recreate the model exactly as it was during that best run.  \n\n**best_model, best_batch_size = create_encoder_decoder_transformer(best_trial)** calls our model-building function again, using the best trial's parameters.\n  \nSince we are passing the best_trial, the same architecture and hyperparameter configuration that gave us the best performance before will now be reproduced.","metadata":{}},{"cell_type":"code","source":"# Best Trial\nbest_trial = study.best_trial\n\n# Recreate best model\nbest_model, best_batch_size = create_encoder_decoder_transformer(best_trial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:07:27.067864Z","iopub.execute_input":"2025-07-20T16:07:27.068657Z","iopub.status.idle":"2025-07-20T16:07:28.345591Z","shell.execute_reply.started":"2025-07-20T16:07:27.068632Z","shell.execute_reply":"2025-07-20T16:07:28.345026Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"In this phase of the project, the encoder-decoder Transformer model is trained using the best hyperparameters identified through Optuna. We will train the model with the best hyperparameters using two important Keras callbacks: ModelCheckpoint and EarlyStopping.  \n  \nThe **ModelCheckpoint** callback is configured to monitor the validation loss (val_loss) during training. It saves the model only when a new minimum in validation loss is reached, ensuring that only the best-performing model across all epochs is preserved. This best model is stored in the file best_model.keras, which can later be reloaded.  \n  \nThe **EarlyStopping** callback monitors the same validation loss metric and halts training if no improvement is observed over a specified number of epochs. This prevents unnecessary training beyond the point of optimal performance. Moreover, the parameter restore_best_weights=True ensures that once training stops early, the model reverts to the weights from the epoch with the best validation performance.  \n  \nThe training itself is conducted by fitting the model to a pair of input datasets: the encoder input (X_train, the descriptions) and the decoder input (decoder_input_train, the target sequence without the final token). The model learns to predict the correct next tokens (decoder_target_train) during training. The validation data serves to monitor the model’s generalization capabilities and guide the callbacks.  \n  \nThe batch size used here comes from the best-performing Optuna trial, helping to balance memory usage and performance.","metadata":{}},{"cell_type":"code","source":"# Define the ModelCheckpoint callback to save the model with the best validation loss\ncheckpoint = ModelCheckpoint(\n    'best_model.keras',       # File path where the best model will be saved\n    monitor='val_loss',       # Monitor validation loss\n    mode='min',               # Lower val_loss = better performance\n    save_best_only=True,      # Only save if this epoch is better than previous ones\n    verbose=1                 # Print when the model is saved\n)\n\n\n# Callbacks: Pruning und optional EarlyStopping\ncallbacks = [\n    EarlyStopping(patience=3,   # If training doesn’t improve for x consecutive epochs, training stops early\n    monitor='val_loss',         \n    restore_best_weights=True), # Ensures the model reverts to the best-performing epoch (not the final one)\n    checkpoint\n]\n\nhistory = best_model.fit(\n    [X_train, decoder_input_train],      # Encoder and decoder inputs\n    decoder_target_train,                # Decoder target output\n    validation_data=([X_valid, decoder_input_valid], decoder_target_valid),\n    epochs=15,\n    batch_size=best_batch_size,          # Batch size from the best Optuna trial\n    callbacks=callbacks,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:07:33.471686Z","iopub.execute_input":"2025-07-20T16:07:33.472243Z","iopub.status.idle":"2025-07-20T16:16:42.401712Z","shell.execute_reply.started":"2025-07-20T16:07:33.472221Z","shell.execute_reply":"2025-07-20T16:16:42.401160Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.0159 - loss: 8.5797\nEpoch 1: val_loss improved from inf to 8.05147, saving model to best_model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 407ms/step - accuracy: 0.0160 - loss: 8.5760 - val_accuracy: 0.0037 - val_loss: 8.0515\nEpoch 2/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.0349 - loss: 6.7848\nEpoch 2: val_loss improved from 8.05147 to 7.91387, saving model to best_model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 313ms/step - accuracy: 0.0349 - loss: 6.7843 - val_accuracy: 0.0160 - val_loss: 7.9139\nEpoch 3/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.0518 - loss: 6.2723\nEpoch 3: val_loss improved from 7.91387 to 7.85449, saving model to best_model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 303ms/step - accuracy: 0.0518 - loss: 6.2719 - val_accuracy: 0.0185 - val_loss: 7.8545\nEpoch 4/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.0597 - loss: 5.9172\nEpoch 4: val_loss improved from 7.85449 to 7.84849, saving model to best_model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 308ms/step - accuracy: 0.0597 - loss: 5.9170 - val_accuracy: 0.0195 - val_loss: 7.8485\nEpoch 5/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.0684 - loss: 5.6132\nEpoch 5: val_loss improved from 7.84849 to 7.82510, saving model to best_model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 307ms/step - accuracy: 0.0684 - loss: 5.6130 - val_accuracy: 0.0222 - val_loss: 7.8251\nEpoch 6/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.0729 - loss: 5.3540\nEpoch 6: val_loss did not improve from 7.82510\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 302ms/step - accuracy: 0.0729 - loss: 5.3539 - val_accuracy: 0.0225 - val_loss: 7.8514\nEpoch 7/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.0772 - loss: 5.1034\nEpoch 7: val_loss did not improve from 7.82510\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 302ms/step - accuracy: 0.0772 - loss: 5.1034 - val_accuracy: 0.0250 - val_loss: 7.8603\nEpoch 8/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.0871 - loss: 4.8869\nEpoch 8: val_loss did not improve from 7.82510\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 302ms/step - accuracy: 0.0871 - loss: 4.8869 - val_accuracy: 0.0250 - val_loss: 7.9427\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"We plot training and validation accuracy as well as training and validation loss to see how closely the validation cuves are tracking the training curves.","metadata":{}},{"cell_type":"code","source":"# Function to plot Loss and Accuracy\ndef plot_training_history(history):\n    \"\"\"\n    Plots the training and validation loss and accuracy from the history object.\n\n    Parameters:\n    history (History): The history object returned by the fit method of a Keras model.\n    \"\"\"\n    fig = plt.figure(figsize=(10, 10), facecolor='white')\n\n    # Plotting Loss\n    ax1 = fig.add_subplot(2, 2, 1, facecolor='white')\n    ax1.plot(history.history['loss'], label='Training Loss')\n    ax1.plot(history.history['val_loss'], label='Validation Loss')\n    ax1.legend(facecolor='white')\n    ax1.set_title('Training Loss vs Validation Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.grid(True, linestyle='--', linewidth=0.5)\n\n    # Plotting Accuracy\n    ax2 = fig.add_subplot(2, 2, 2, facecolor='white')\n    ax2.plot(history.history['accuracy'], label='Training Accuracy')\n    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    ax2.legend(facecolor='white')\n    ax2.set_title('Training Accuracy vs Validation Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.grid(True, linestyle='--', linewidth=0.5)\n\n    plt.tight_layout()\n    plt.show()\n\nplot_training_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:17:08.768384Z","iopub.execute_input":"2025-07-20T16:17:08.768636Z","iopub.status.idle":"2025-07-20T16:17:09.383164Z","shell.execute_reply.started":"2025-07-20T16:17:08.768620Z","shell.execute_reply":"2025-07-20T16:17:09.382472Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"In the early epochs, there is an improvement in validation loss and accuracy. This indicates that the model was able to learn and generalize in the initial phases of training.   \nThen the improvements in validation loss become smaller.","metadata":{}},{"cell_type":"markdown","source":"We will load the best model. Because of these @register_keras_serializable() decorators we used earlier, Keras knows how to serialize and deserialize them properly and we do not need to manually pass them again when calling load_model().","metadata":{}},{"cell_type":"code","source":"# Load best model from file\ntform_model = load_model('best_model.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:17:42.671518Z","iopub.execute_input":"2025-07-20T16:17:42.671999Z","iopub.status.idle":"2025-07-20T16:17:43.862487Z","shell.execute_reply.started":"2025-07-20T16:17:42.671976Z","shell.execute_reply":"2025-07-20T16:17:43.861900Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## Test Texts\n  \nThe following function generate_title takes an input description and generates a title. It first encodes the description using the Byte-Pair Encoding (BPE) tokenizer, making sure it matches the expected input length for the encoder. It also retrieves the special sos (start-of-sequence) and eos (end-of-sequence) token IDs that mark the beginning and end of the title generation process.  \n  \nThe decoding process is performed step-by-step in a loop. It starts with a decoder input initialized with the sos token. At each step, the function pads the current decoder input (to ensure a consistent shape), passes it together with the encoded description to the model and selects the most probable next token using argmax over the predicted probability distribution.   \n  \nIf the model predicts the eos token, the loop stops early. Otherwise, the predicted token is appended to the decoder input and decoding continues.  \n  \nAfter decoding is complete, the function converts the predicted token IDs back into strings using the tokenizer and reconstructs the final title text. BPE token artifacts (like ▁ used to indicate spaces) are removed, and the final title is cleaned and returned.","metadata":{}},{"cell_type":"code","source":"def generate_title(description_text, tokenizer, model, max_len_desc, max_len_title):\n    # Tokenize and pad the input description\n    input_ids = bpe_encode([description_text], tokenizer, max_len_desc)\n\n    # Get the special token IDs\n    sos_id = tokenizer.token_to_id(\"<sos>\")\n    eos_id = tokenizer.token_to_id(\"<eos>\")\n    assert sos_id is not None and eos_id is not None, \"Special tokens missing in tokenizer!\"\n\n    # Start the decoder input with the <sos> token\n    decoder_input = [sos_id]\n\n    for i in range(max_len_title):\n        # Pad the decoder input to match the required input shape\n        padded_decoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n            [decoder_input],\n            maxlen=max_len_title - 1,\n            padding='post'\n        )\n\n        # Predict the next token probabilities\n        predictions = model.predict([input_ids, padded_decoder_input], verbose=0)\n\n        # Select the token with the highest probability at the current decoding position\n        current_pos = len(decoder_input) - 1\n        next_token_id = np.argmax(predictions[0][current_pos])\n\n        # If end-of-sequence token is predicted, stop generation\n        if next_token_id == eos_id:\n            break\n\n        # Otherwise, append the token and continue decoding\n        decoder_input.append(next_token_id)\n\n    # Convert token IDs to string tokens and reconstruct the final title\n    tokens = [tokenizer.id_to_token(id) for id in decoder_input[1:]]  # skip <sos>\n    return \" \".join(tokens).replace(\"▁\", \" \").strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:17:50.475355Z","iopub.execute_input":"2025-07-20T16:17:50.476022Z","iopub.status.idle":"2025-07-20T16:17:50.481890Z","shell.execute_reply.started":"2025-07-20T16:17:50.475997Z","shell.execute_reply":"2025-07-20T16:17:50.481316Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"Now let's see how our Transformer model performs on the test data.","metadata":{}},{"cell_type":"code","source":"# Loop over the first 3 test descriptions and generate titles\nfor i in range(3):\n    sample_description = df_test.loc[i, 'Test_Description']\n    original_title = df_test.loc[i, 'Test_Title']  \n    \n    generated_title = generate_title(\n        model=tform_model,\n        tokenizer=bpe_tokenizer,\n        description_text=sample_description,\n        max_len_desc=max_len_desc,\n        max_len_title=max_len_title\n    )\n    \n    print(f\"Original Description #{i+1}:\\n{sample_description}\\n\")\n    print(f\"Original Title #{i+1}: {original_title}\\n\")\n    print(f\"Generated Title #{i+1}: {generated_title}\\n\")\n    print(\"-\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T16:17:53.779696Z","iopub.execute_input":"2025-07-20T16:17:53.780203Z","iopub.status.idle":"2025-07-20T16:17:58.186927Z","shell.execute_reply.started":"2025-07-20T16:17:53.780183Z","shell.execute_reply":"2025-07-20T16:17:58.186364Z"}},"outputs":[{"name":"stdout","text":"Original Description #1:\nstarting over sucks.when we moved to west virginia right before my senior year, i'd pretty much resigned myself to thick accents, dodgy internet access, and a whole lot of boring… until i spotted my hot neighbor, with his looming height and eerie green eyes. things were looking up.and then he opened his mouth.daemon is infuriating. arrogant. stab-worthy. we do not get alon starting over sucks.when we moved to west virginia right before my senior year, i'd pretty much resigned myself to thick accents, dodgy internet access, and a whole lot of boring… until i spotted my hot neighbor, with his looming height and eerie green eyes. things were looking up.and then he opened his mouth.daemon is infuriating. arrogant. stab-worthy. we do not get along. at all. but when a stranger attacks me and daemon literally freezes time with a wave of his hand, well, something… unexpected happens. the hot alien living next door marks me.you heard me. alien. turns out daemon and his sister have a galaxy of enemies wanting to steal their abilities, and daemon's touch has me lit up like the vegas strip. the only way i'm getting out of this alive is by sticking close to daemon until my alien mojo fades. if i don't kill him first, that is.\n\nOriginal Title #1: obsidian (lux #1)\n\nGenerated Title #1: the art\n\n--------------------------------------------------------------------------------\nOriginal Description #2:\nthe age of genius explores the eventful intertwining of outward event and inner intellectual life to tell, in all its richness and depth, the story of the 17th century in europe. it was a time of creativity unparalleled in history before or since, from science to the arts, from philosophy to politics. acclaimed philosopher and historian a.c. grayling points to three primar the age of genius explores the eventful intertwining of outward event and inner intellectual life to tell, in all its richness and depth, the story of the 17th century in europe. it was a time of creativity unparalleled in history before or since, from science to the arts, from philosophy to politics. acclaimed philosopher and historian a.c. grayling points to three primary factors that led to the rise of vernacular (popular) languages in philosophy, theology, science, and literature; the rise of the individual as a general and not merely an aristocratic type; and the invention and application of instruments and measurement in the study of the natural world.grayling vividly reconstructs this unprecedented era and breathes new life into the major figures of the seventeenth century intelligentsia who span literature, music, science, art, and philosophy--shakespeare, monteverdi, galileo, rembrandt, locke, newton, descartes, vermeer, hobbes, milton, and cervantes, among many more. during this century, a fundamentally new way of perceiving the world emerged as reason rose to prominence over tradition, and the rights of the individual took center stage in philosophy and politics, a paradigmatic shift that would define western thought for centuries to come.\n\nOriginal Title #2: the age of genius: the seventeenth century and the birth of the modern mind\n\nGenerated Title #2: the art\n\n--------------------------------------------------------------------------------\nOriginal Description #3:\ndespite the tumor-shrinking medical miracle that has bought her a few years, hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. but when a gorgeous plot twist named augustus waters suddenly appears at cancer kid support group, hazel's story is about to be completely rewritten.insightful, bold, irreverent, and raw, the fault in our stars despite the tumor-shrinking medical miracle that has bought her a few years, hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. but when a gorgeous plot twist named augustus waters suddenly appears at cancer kid support group, hazel's story is about to be completely rewritten.insightful, bold, irreverent, and raw, the fault in our stars is award-winning author john green's most ambitious and heartbreaking work yet, brilliantly exploring the funny, thrilling, and tragic business of being alive and in love.\n\nOriginal Title #3: the fault in our stars\n\nGenerated Title #3: the art\n\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"The model consistently outputs the same phrase, indicating a generation failure.\n  \nTitle generation is inherently difficult, as book titles are often creative, abstract and sometimes loosely related to the description. The model was trained on a very small dataset, limiting its ability to generalize or learn title styles effectively.\nThe architecture was constrained by limited computing resources, which further restricted training depth and capacity.\n  \nGiven the limitations — small data, limited compute and the creative nature of the task — these results are understandable.","metadata":{}}]}